{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "cDTLUOBKw2KS",
    "outputId": "8a69a902-75e8-4103-d621-d153507da51d"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(60000, 1, 28, 28)\n",
      "(60000, 10)\n",
      "(10000, 1, 28, 28)\n"
     ]
    }
   ],
   "source": [
    "import urllib.request\n",
    "import os.path\n",
    "import gzip\n",
    "import pickle\n",
    "import os\n",
    "import numpy as np\n",
    "import sys,os\n",
    "\n",
    "file_path = ['./data/train-images-idx3-ubyte.gz','./data/train-labels-idx1-ubyte.gz','./data/t10k-images-idx3-ubyte.gz','./data/t10k-labels-idx1-ubyte.gz']\n",
    "\n",
    "def file_load(path):\n",
    "  if path.find('images') != -1:\n",
    "    with gzip.open(path, 'rb') as f:\n",
    "      data = np.frombuffer(f.read(), np.uint8, offset=16)\n",
    "    data = data.reshape(-1, 784)\n",
    "    return data\n",
    "  else:\n",
    "    with gzip.open(path, 'rb') as f:\n",
    "      labels = np.frombuffer(f.read(), np.uint8, offset=8)\n",
    "    return labels\n",
    "\n",
    "dataset = {}\n",
    "dataset['train_img'] =  file_load(file_path[0])\n",
    "dataset['train_label'] = file_load(file_path[1])    \n",
    "dataset['test_img'] = file_load(file_path[2])\n",
    "dataset['test_label'] = file_load(file_path[3])\n",
    "\n",
    "\n",
    "#normalize \n",
    "dataset['train_img'] = dataset['train_img'].astype(np.float32)\n",
    "dataset['train_img'] /= 255.0\n",
    "dataset['test_img'] = dataset['test_img'].astype(np.float32)\n",
    "dataset['test_img'] /= 255.0\n",
    "\n",
    "#one_hot_label\n",
    "T = np.zeros((dataset['train_label'].size, 10))\n",
    "for idx, row in enumerate(T):\n",
    "  row[dataset['train_label'][idx]] = 1\n",
    "dataset['train_label'] =T\n",
    "T = np.zeros((dataset['test_label'].size, 10))\n",
    "for idx, row in enumerate(T):\n",
    "  row[dataset['test_label'][idx]] = 1\n",
    "dataset['test_label'] =T\n",
    "#not flatten\n",
    "for key in ('train_img', 'test_img'):\n",
    "  dataset[key] = dataset[key].reshape(-1, 1, 28, 28)\n",
    "\n",
    "\n",
    "(X_train, Y_train), (X_test, Y_test) = (dataset['train_img'], dataset['train_label']), (dataset['test_img'], dataset['test_label']) \n",
    "#(X_train, Y_train), (X_test, Y_test) = load_mnist(normalize=True, one_hot_label=True)\n",
    "print(X_train.shape)\n",
    "print(Y_train.shape)\n",
    "print(X_test.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "fVBqxInX0cv0",
    "outputId": "5b57df13-8914-46ee-bc8e-f33f1132af51"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "12000\n",
      "(48000, 1, 28, 28) (12000, 1, 28, 28)\n",
      "(48000, 10) (12000, 10)\n"
     ]
    }
   ],
   "source": [
    "import random\n",
    "def split_validation(X_train, n=0.4):\n",
    "  #X_train = random.shuffle(X_train)\n",
    "  num = int(X_train.shape[0] * 0.4)\n",
    "  print(num)\n",
    "  return X_train[num:], X_train[:num], Y_train[num:], Y_train[:num] #train, vallidation\n",
    "\n",
    "X_train1, X_train_valid, Y_train1, Y_train_valid = split_validation(X_train,n=0.2)\n",
    "print(X_train1.shape, X_train_valid.shape)\n",
    "print(Y_train1.shape, Y_train_valid.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "JZiAI1VW8omt",
    "outputId": "361f5003-46a3-4292-dcf8-9bccd1d4af35"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(1, 28, 28)\n",
      "(32, 1, 28, 28)\n"
     ]
    }
   ],
   "source": [
    "print(X_train1[0].shape)\n",
    "batch = 32\n",
    "batch_size = np.random.choice(X_train1.shape[0], batch) #array로 return\n",
    "X_train_b = X_train1[batch_size]\n",
    "Y_train_b = Y_train1[batch_size]\n",
    "print(X_train_b.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "id": "sZJ956bY1TcJ"
   },
   "outputs": [],
   "source": [
    "class ReLU:\n",
    "   def __init__(self):\n",
    "     self.x_bool = None\n",
    "\n",
    "   def forward(self,x):\n",
    "     #print('RELU_forward')\n",
    "     #print('RELU_forward.x: ',x.shape)\n",
    "     #print('ReLU_forward')\n",
    "     self.x_bool = (x<=0) #T/F bool Array\n",
    "     relu = x.copy()\n",
    "     relu[self.x_bool] = 0\n",
    "     return relu\n",
    "\n",
    "   def backward(self,back):\n",
    "     #print('RELU_backward')\n",
    "     #print('ReLU_backward')\n",
    "     back[self.x_bool] = 0\n",
    "     return back\n",
    "\n",
    "class LReLU:\n",
    "  def __init__(self):\n",
    "    self.x_bool = None\n",
    "  \n",
    "  def forward(self,x):\n",
    "    self.x_bool = (x<=0)\n",
    "    lrelu = x.copy()\n",
    "    lrelu[self.x_bool] *= 0.1\n",
    "    return lrelu\n",
    "\n",
    "  def backward(self,back):\n",
    "    back[self.x_bool] *= 0.1\n",
    "    return back\n",
    "   \n",
    "class Softmax_Cross_Entropy_Error:\n",
    "  def __init__(self):\n",
    "    self.loss = 0\n",
    "    self.p = 0\n",
    "    self.y = 0\n",
    "\n",
    "  def forward(self, p, y):\n",
    "    #print('Softmax_Cross_Entropy_Error_forward')\n",
    "    self.y = y\n",
    "    self.p = softmax(p)\n",
    "    self.loss = cross_entropy_error(self.p, self.y)\n",
    "    return self.loss\n",
    "\n",
    "  def backward(self, back = 1):\n",
    "    #print('Softmax_Cross_Entropy_Error_backward')\n",
    "    batch_size = self.y.shape[0]\n",
    "    return (self.p - self.y) / batch_size\n",
    "class Linear: #바꿔야됨!!!\n",
    "  def __init__(self, W, b):\n",
    "    self.W = W\n",
    "    self.b = b\n",
    "        \n",
    "    self.x = None\n",
    "    self.original_x_shape = None\n",
    "    # 가중치와 편향 매개변수의 미분\n",
    "    self.dW = None\n",
    "    self.db = None\n",
    "\n",
    "  def forward(self, x):\n",
    "    #print('Linear.forward')\n",
    "    #print('Linear.forward.x: ',x.shape)\n",
    "    #print('Linear.forward.w: ',self.W.shape)\n",
    "    # 텐서 대응\n",
    "    self.original_x_shape = x.shape\n",
    "    x = x.reshape(x.shape[0], -1)\n",
    "    #print('after: ',x.shape)\n",
    "    #print('self.b: ',self.b.shape)\n",
    "    self.x = x\n",
    "\n",
    "    out = np.dot(self.x, self.W) + self.b\n",
    "\n",
    "    return out\n",
    "\n",
    "  def backward(self, dout):\n",
    "    #print('Linear.backward')\n",
    "    dx = np.dot(dout, self.W.T)\n",
    "    self.dW = np.dot(self.x.T, dout)\n",
    "    self.db = np.sum(dout, axis=0)\n",
    "        \n",
    "    dx = dx.reshape(*self.original_x_shape)  # 입력 데이터 모양 변경(텐서 대응)\n",
    "    return dx\n",
    "#각종 함수들\n",
    "def softmax(x):\n",
    "  #print('_softmax')\n",
    "  #if x.ndim == 2:\n",
    "  x = x.T\n",
    "  x = x - np.max(x, axis=0)\n",
    "  y = np.exp(x) / np.sum(np.exp(x), axis=0)\n",
    "  return y.T\n",
    "def cross_entropy_error(p,y):\n",
    "  #cross_entropy_error.p:  (100, 40, 13, 10)\n",
    "  #cross_entropy_error.y:  (100, 10)\n",
    "  #print('cross_entropy_error')\n",
    "  #print('cross_entropy_error.p: ',p.shape)\n",
    "  #print('cross_entropy_error.y: ',y.shape)\n",
    "  if p.ndim == 1:\n",
    "      y = y.reshape(1, y.size)\n",
    "      p = p.reshape(1, p.size)\n",
    "        \n",
    "    # 훈련 데이터가 원-핫 벡터라면 정답 레이블의 인덱스로 반환\n",
    "  if y.size == p.size:\n",
    "      y = y.argmax(axis=1)\n",
    "             \n",
    "  batch_size = p.shape[0]\n",
    "  return -np.sum(np.log(p[np.arange(batch_size), y] + 1e-7)) / batch_size"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "-N20QXjU-nnR",
    "outputId": "b242ccab-d687-42ff-dfbf-e448a394bb10"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(100, 1, 28, 28)\n"
     ]
    }
   ],
   "source": [
    "batch=100\n",
    "batch_size = np.random.choice(X_train1.shape[0], batch) #array로 return\n",
    "X_train_b = X_train1[batch_size]\n",
    "Y_train_b = Y_train1[batch_size]\n",
    "print(X_train_b.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "id": "84pEWtRXy7ru"
   },
   "outputs": [],
   "source": [
    "def im2col(input_image, filter, stride=1, pad=0):\n",
    "  output_height, output_width = cal_output(input_image, filter, stride, pad)\n",
    "  if type(filter) != tuple:\n",
    "    output_col = np.zeros((int(input_image.shape[0]), int(input_image.shape[1]), int(filter.shape[2]), int(filter.shape[3]), int(output_height), int(output_width)))\n",
    "    fh = int(filter.shape[2])\n",
    "    fw = int(filter.shape[3])\n",
    "  else:\n",
    "    fh = filter[0]\n",
    "    fw = filter[1]\n",
    "    output_col = np.zeros((int(input_image.shape[0]), int(input_image.shape[1]), int(filter[0]), int(filter[1]), int(output_height), int(output_width)))\n",
    "  pad_img = np.pad(input_image, [(0,0),(0,0),(pad,pad),(pad,pad)], 'constant')\n",
    "\n",
    "  for i in range(fh):#각 filter의 원소마다 연산해 줄 이미지 추출\n",
    "    y_max = i + stride * output_height\n",
    "    for j in range(fw):\n",
    "      x_max = j + stride * output_width\n",
    "      output_col[:, :, i, j, :, :] = pad_img[:, :, i: y_max: stride, j:x_max:stride]\n",
    "  output_col = output_col.transpose(0,4,5,1,2,3).reshape(input_image.shape[0]*output_height*output_width,-1)\n",
    "  return output_col\n",
    "\n",
    "#https://cding.tistory.com/112\n",
    "def col2im(col, input_image, filter, stride=1, pad=0):\n",
    "  output_height, output_width = cal_output(input_image, filter, stride, pad)\n",
    "  if type(filter) != tuple:\n",
    "    col = col.reshape(int(input_image.shape[0]), int(output_height), int(output_width), int(input_image.shape[1]), int(filter.shape[2]), int(filter.shape[3])).transpose(0, 3, 4, 5, 1, 2)\n",
    "    fh = int(filter.shape[2])\n",
    "    fw = int(filter.shape[3])\n",
    "  else:\n",
    "    fh = filter[0]\n",
    "    fw = filter[1]\n",
    "    col = col.reshape(int(input_image.shape[0]), int(output_height), int(output_width), int(input_image.shape[1]), int(filter[1]), int(filter[1])).transpose(0, 3, 4, 5, 1, 2)\n",
    "  \n",
    "  img = np.zeros((int(input_image.shape[0]), int(input_image.shape[1]), int(input_image.shape[2]) + 2 * pad + stride - 1, int(input_image.shape[3]) + 2 * pad + stride - 1))\n",
    "  for y in range(fw):\n",
    "      y_max = y + stride * output_height\n",
    "      for x in range(fh):\n",
    "          x_max = x + stride * output_width\n",
    "          img[:, :, y:y_max:stride, x:x_max:stride] += col[:, :, y, x, :, :]\n",
    "\n",
    "  return img[:, :, pad:input_image.shape[2] + pad, pad:input_image.shape[3] + pad]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "id": "q5eEZ9dQN-Vm"
   },
   "outputs": [],
   "source": [
    "def cal_output(input_img, filter, stride, pad):\n",
    "  if type(filter) != tuple:\n",
    "    output_height = (input_img.shape[2] + 2*pad - filter.shape[2])//stride + 1 #int로 만들어주기 위해 //를 사용\n",
    "    output_width = (input_img.shape[3] + 2*pad - filter.shape[3])//stride + 1\n",
    "  else: #Pooling 계층일 때\n",
    "    output_height = (input_img.shape[2] + 2*pad - filter[0])//stride + 1\n",
    "    output_width = (input_img.shape[3] + 2*pad - filter[1])//stride + 1\n",
    "  \n",
    "  return output_height, output_width"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "id": "63vb8Ddz1gEJ"
   },
   "outputs": [],
   "source": [
    "import numpy\n",
    "\n",
    "class Maxpool:\n",
    "  def __init__(self, pool_size ,stride,pad): #stride, pad 초기화 안함\n",
    "    self.pool = pool_size #(2,2) tuple형태, tuple도 indexing 가능\n",
    "    self.stride = stride\n",
    "    self.pad = pad\n",
    "    self.col_max = None\n",
    "    self.x = None\n",
    "    \n",
    "  def forward(self, x):\n",
    "    #print('Maxpool_forward')\n",
    "    self.x = x\n",
    "    output_height, output_width = cal_output(x, self.pool, self.stride, pad = 0)\n",
    "    _col = im2col(x, self.pool, self.stride, self.pad).reshape(-1, self.pool[0]*self.pool[1])\n",
    "\n",
    "    col_max = np.max(_col, axis = 1) #행단위로 max찾아\n",
    "    self.col_max = np.argmax(_col, axis = 1) #max의 index값\n",
    "    #print('maxpool_forward_output: ',col_max.reshape(x.shape[0], output_height, output_width, x.shape[1]).transpose(0,3,1,2).shape)\n",
    "    return col_max.reshape(x.shape[0], output_height, output_width, x.shape[1]).transpose(0,3,1,2)\n",
    "  \n",
    "  def backward(self, back): #이름만 바꿨으므로 수정필요\n",
    "    #print('Maxpool_backward')\n",
    "\n",
    "    back = back.transpose(0, 2, 3, 1)\n",
    "        \n",
    "    pool_size = self.pool[0] * self.pool[1]\n",
    "    dmax = np.zeros((back.size, pool_size))\n",
    "    dmax[np.arange(self.col_max.size), self.col_max.flatten()] = back.flatten()\n",
    "    dmax = dmax.reshape(back.shape + (pool_size,)) \n",
    "        \n",
    "    dcol = dmax.reshape(dmax.shape[0] * dmax.shape[1] * dmax.shape[2], -1)\n",
    "    #print('maxpool_dcol: ',dcol.shape) #maxpool_dcol:  (16900, 160)\n",
    "    #print('dcol: ',dcol)\n",
    "    dx = col2im(dcol, self.x, self.pool, self.stride, self.pad)\n",
    "    return dx\n",
    "\n",
    "\n",
    "class Conv: #filter가 정사각, 직사각 둘다 가능\n",
    "  def __init__(self, filter_weights, bias, stride = 1, pad = 0):\n",
    "    #print('__init__COnv')\n",
    "    self.filter = filter_weights\n",
    "    self.bias = bias\n",
    "    self.stride = stride\n",
    "    self.pad = pad\n",
    "    self.d_filter = None\n",
    "    self.db = None\n",
    "    self.input = None\n",
    "    self.output = None\n",
    "\n",
    "  def forward(self, x):\n",
    "    #print('conv_forward')\n",
    "    #print('conv_x.shape: ',x.shape)\n",
    "    #print('conv_filter.type: ', type(self.filter))\n",
    "    #print('conv_filter.shape: ',self.filter.shape)\n",
    "    self.x = x\n",
    "    output_height = (x.shape[2] + 2*self.pad - self.filter.shape[2])//self.stride + 1\n",
    "    output_width = (x.shape[3] + 2*self.pad - self.filter.shape[3])//self.stride + 1\n",
    "    \n",
    "    image_col = im2col(x, self.filter, self.stride, self.pad)\n",
    "    self.input = image_col\n",
    "    filter_col = self.filter.reshape(self.filter.shape[0],-1).T\n",
    "    self.output= filter_col\n",
    "    #print('conv_forward..image_col: ',image_col.shape)\n",
    "    #print('conv_forward..filter_col: ',filter_col.shape)\n",
    "    out_col = np.dot(image_col,filter_col) + self.bias\n",
    "    \n",
    "    return out_col.reshape(int(x.shape[0]),int(output_height), output_width, -1).transpose(0,3,1,2)\n",
    "  \n",
    "  def backward(self, back):\n",
    "    #print('conv_backward')\n",
    "    #print('conv_back: ',back.shape)\n",
    "    #print('conv_input: ',self.input.shape)\n",
    "    #print('conv_output: ',self.output.shape)\n",
    "\n",
    "    back = back.transpose(0,2,3,1).reshape(-1,self.filter.shape[0])\n",
    "    self.db = np.sum(back, axis=0)\n",
    "    self.d_filter = np.dot(self.input.T, back).transpose(1,0).reshape(self.filter.shape[0],self.filter.shape[1] , self.filter.shape[2], self.filter.shape[3])\n",
    "    back_propagation = np.dot(back, self.output.T)\n",
    "    return col2im(back_propagation, self.x, self.filter, self.stride, self.pad)\n",
    "    '''self.d_filter = np.dot(self.input.T, back).transpose(1, 0).reshape(self.filter.shape[0],self.filter.shape[1] , self.filter.shape[2], self.filter.shape[3])\n",
    "    self.db = np.sum(back, axis=0)\n",
    "    back_propagation = np.dot(back, self.output.T)\n",
    "\n",
    "    return col2im(back_propagation, self.x, self.filter, self.stride, self.pad) #col2im 함수 내가 만들어야해(input달라)'''"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "id": "n6r3_09W2CbH"
   },
   "outputs": [],
   "source": [
    "class Two_layer_CNN: # Conv-ReLU-MaxPool - Conv-ReLU-MaxPool -Linear-SoftMax (The input and output size of NN: input 28x28, output 10)\n",
    "  def __init__(self, filter_num = 20, filter_size=(5,5), pad = 0, stride = 1):\n",
    "    self.input_dim = 28 #pool의 pad는 여기 안에서 수정할 수 있도록\n",
    "    self.filter_num = filter_num\n",
    "    self.filter_size = filter_size\n",
    "    self.pad = pad\n",
    "    self.stride = stride\n",
    "    self.pool_pad = 0\n",
    "    self.pool_size = (2,2) #정사각형으로 고정 !! --> 직사각형으로도 고칠 수 있긴 함..\n",
    "    self.pool_stride = 1\n",
    "    print(self.filter_size)\n",
    "    self.output_height_first_layer = ((self.input_dim + 2*self.pad - self.filter_size[0]) // self.stride) +1\n",
    "    self.output_width_first_layer = ((self.input_dim + 2*self.pad - self.filter_size[1]) // self.stride) + 1\n",
    "    #(0,0,28,28)에서 0,0은 임의의 값.함수사용하기 위해 아무숫자넣은 것.\n",
    "\n",
    "    self.pool_output_first_layer_h = ((self.output_height_first_layer + 2*self.pool_pad - self.pool_size[0])//self.pool_stride) +1\n",
    "    self.pool_output_first_layer_w = ((self.output_width_first_layer + 2*self.pool_pad - self.pool_size[1])//self.pool_stride) +1\n",
    "\n",
    "    self.output_height_second_layer = ((self.pool_output_first_layer_h + 2*self.pad - self.filter_size[0]*2)// self.stride ) +1\n",
    "    self.output_width_second_layer = ((self.pool_output_first_layer_w + 2*self.pad - self.filter_size[1]*2)//self.stride) + 1\n",
    "    self.pool_output_second_layer = ((self.output_height_second_layer + 2*self.pool_pad - self.pool_size[0])//self.pool_stride ) +1\n",
    "    #???????pool_size 정사각형으로만 고려해야 하나??\n",
    "    #pool_size가 직사각형이면 weight값을 어떻게 설정하지????????\n",
    "    #int(filter_num * (self.output_height/2) * (self.output_width/2)) #w2가 filter_num*2이므로 그 출력값에 맞춰서\n",
    "\n",
    "    self.weights = {}\n",
    "    self.weights['w1'] = np.random.randn(filter_num, 1, self.filter_size[0], self.filter_size[1]) #일단 filter 직사각형도 허용...!!!!\n",
    "    self.weights['b1'] = np.random.randn(filter_num)\n",
    "    self.weights['w2'] = np.random.randn(self.filter_num*2,self.filter_num, self.filter_size[0] * 2, self.filter_size[1] *2) #일단 그냥 *2해봤음. .. 맞는지 모르겠음!!!!\n",
    "    self.weights['b2'] = np.random.randn(self.filter_num*2)\n",
    "    print('b2: ',self.weights['b2'].shape)\n",
    "    print('self.pool_output: ',self.pool_output_second_layer)\n",
    "    self.weights['w3'] = np.random.randn(self.pool_output_second_layer * self.pool_output_second_layer * self.filter_num*2, 10) #hidden_size = 50, output_size = 10 #pool_size 정사각형 취급\n",
    "    self.weights['b3'] = np.random.randn(10)\n",
    "\n",
    "    self.layers = {}\n",
    "    self.layers['CL1'] = Conv(self.weights['w1'], self.weights['b1'], self.stride, self.pad) #1,2층 conv 같은 stride, pad적용!!\n",
    "    self.layers['RL1'] = ReLU()\n",
    "    self.layers['MP1'] = Maxpool(self.pool_size,self.pool_stride,self.pool_pad) #pool size 변화시킬 수도 있음.\n",
    "    self.layers['CL2'] = Conv(self.weights['w2'], self.weights['b2'], self.stride, self.pad)\n",
    "    self.layers['RL2'] = ReLU()\n",
    "    self.layers['MP2'] = Maxpool(self.pool_size,self.pool_stride,self.pool_pad)\n",
    "    self.layers['L1'] = Linear(self.weights['w3'], self.weights['b3'])\n",
    "    self.layers['softmax_cross'] = Softmax_Cross_Entropy_Error()\n",
    "\n",
    "    self.l = ['CL1','RL1','MP1','CL2','RL2','MP2','L1','softmax_cross']\n",
    "\n",
    "  def forward(self, x):\n",
    "    #print('forward')\n",
    "    for layer in self.l:\n",
    "      if layer != 'softmax_cross':\n",
    "        x = self.layers[layer].forward(x)\n",
    "    return x\n",
    "\n",
    "  def loss(self, x, y):\n",
    "    #print('loss')\n",
    "    f = self.forward(x)\n",
    "    loss = self.layers['softmax_cross'].forward(f, y)\n",
    "    return loss\n",
    "\n",
    "  def accuracy(self, x, y):\n",
    "    #print('accuracy')\n",
    "    f = self.forward(x)\n",
    "    p = np.argmax(f, axis = 1) #argmax는 가장 큰 값의 인덱스 값을 반환한다.\n",
    "    #one_hot encoding이니까 if문 적용 x.!!\n",
    "    y = np.argmax(y, axis=1) #행 (1,batch_size)\n",
    "    accuracy = np.sum(y == p) / float(x.shape[0]) #batch_size로 나눠\n",
    "    return accuracy\n",
    "\n",
    "  def back_propagate_train(self,x,y):\n",
    "    #print('back_propagate_train')\n",
    "    loss = self.loss(x,y)\n",
    "    back = self.layers['softmax_cross'].backward(1)\n",
    "    for reversed_layer in reversed(self.l):\n",
    "      #print('back_propa: ', reversed_layer)\n",
    "      back = self.layers[reversed_layer].backward(back)\n",
    "    \n",
    "    gradients = {}\n",
    "    gradients['w1'] = self.layers['CL1'].d_filter\n",
    "    gradients['b1'] = self.layers['CL1'].db\n",
    "    gradients['w2'] = self.layers['CL2'].d_filter\n",
    "    gradients['b2'] = self.layers['CL2'].db\n",
    "    gradients['w3'] = self.layers['L1'].dW\n",
    "    gradients['b3'] = self.layers['L1'].db\n",
    "\n",
    "    return gradients"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "QoWwbddd6w3n",
    "outputId": "3580fc43-89fe-40e9-cfe0-d3e3b3e15f31"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(5, 5)\n",
      "b2:  (40,)\n",
      "self.pool_output:  13\n",
      "__init__COnv\n",
      "__init__COnv\n",
      "(100, 1, 28, 28)\n",
      "(100, 10)\n",
      "back_propagate_train\n",
      "loss\n",
      "forward\n",
      "conv_forward\n",
      "conv_x.shape:  (100, 1, 28, 28)\n",
      "conv_filter.type:  <class 'numpy.ndarray'>\n",
      "conv_filter.shape:  (20, 1, 5, 5)\n",
      "conv_forward..image_col:  (57600, 25)\n",
      "conv_forward..filter_col:  (25, 20)\n",
      "RELU_forward\n",
      "RELU_forward.x:  (100, 20, 24, 24)\n",
      "Maxpool_forward\n",
      "maxpool_forward_output:  (100, 20, 23, 23)\n",
      "conv_forward\n",
      "conv_x.shape:  (100, 20, 23, 23)\n",
      "conv_filter.type:  <class 'numpy.ndarray'>\n",
      "conv_filter.shape:  (40, 20, 10, 10)\n",
      "conv_forward..image_col:  (19600, 2000)\n",
      "conv_forward..filter_col:  (2000, 40)\n",
      "RELU_forward\n",
      "RELU_forward.x:  (100, 40, 14, 14)\n",
      "Maxpool_forward\n",
      "maxpool_forward_output:  (100, 40, 13, 13)\n",
      "Linear.forward\n",
      "Linear.forward.x:  (100, 40, 13, 13)\n",
      "Linear.forward.w:  (6760, 10)\n",
      "after:  (100, 6760)\n",
      "self.b:  (10,)\n",
      "Softmax_Cross_Entropy_Error_forward\n",
      "_softmax\n",
      "cross_entropy_error\n",
      "cross_entropy_error.p:  (100, 10)\n",
      "cross_entropy_error.y:  (100, 10)\n",
      "back_propa:  softmax_cross\n",
      "back_propa:  L1\n",
      "Linear.backward\n",
      "back_propa:  MP2\n",
      "Maxpool_backward\n",
      "maxpool_dcol:  (16900, 160)\n",
      "back_propa:  RL2\n",
      "RELU_backward\n",
      "back_propa:  CL2\n",
      "conv_backward\n",
      "conv_back:  (100, 40, 14, 14)\n",
      "conv_input:  (19600, 2000)\n",
      "conv_output:  (2000, 40)\n",
      "back_propa:  MP1\n",
      "Maxpool_backward\n",
      "maxpool_dcol:  (52900, 80)\n",
      "back_propa:  RL1\n",
      "RELU_backward\n",
      "back_propa:  CL1\n",
      "conv_backward\n",
      "conv_back:  (100, 20, 24, 24)\n",
      "conv_input:  (57600, 25)\n",
      "conv_output:  (25, 20)\n",
      "loss\n",
      "forward\n",
      "conv_forward\n",
      "conv_x.shape:  (48000, 1, 28, 28)\n",
      "conv_filter.type:  <class 'numpy.ndarray'>\n",
      "conv_filter.shape:  (20, 1, 5, 5)\n"
     ]
    },
    {
     "ename": "MemoryError",
     "evalue": "Unable to allocate 5.15 GiB for an array with shape (48000, 24, 24, 1, 5, 5) and data type float64",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mMemoryError\u001b[0m                               Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-11-89e03ddabd1d>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m     34\u001b[0m     \u001b[0mx_plot\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mappend\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mn\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;31m#count epoch\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     35\u001b[0m     \u001b[0mn\u001b[0m\u001b[1;33m+=\u001b[0m\u001b[1;36m1\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 36\u001b[1;33m     \u001b[0mtrain_l\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mmodel\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mloss\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mX_train1\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0mY_train1\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;31m#전체 trainset loss계산\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     37\u001b[0m     \u001b[0mvalid_l\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mmodel\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mloss\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mX_train_valid\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mY_train_valid\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     38\u001b[0m     \u001b[0mtrain_loss\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mappend\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mtrain_l\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m<ipython-input-10-4c84a08175f0>\u001b[0m in \u001b[0;36mloss\u001b[1;34m(self, x, y)\u001b[0m\n\u001b[0;32m     55\u001b[0m   \u001b[1;32mdef\u001b[0m \u001b[0mloss\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mx\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0my\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     56\u001b[0m     \u001b[0mprint\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m'loss'\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 57\u001b[1;33m     \u001b[0mf\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mforward\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mx\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     58\u001b[0m     \u001b[0mloss\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mlayers\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;34m'softmax_cross'\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mforward\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mf\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0my\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     59\u001b[0m     \u001b[1;32mreturn\u001b[0m \u001b[0mloss\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m<ipython-input-10-4c84a08175f0>\u001b[0m in \u001b[0;36mforward\u001b[1;34m(self, x)\u001b[0m\n\u001b[0;32m     50\u001b[0m     \u001b[1;32mfor\u001b[0m \u001b[0mlayer\u001b[0m \u001b[1;32min\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0ml\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     51\u001b[0m       \u001b[1;32mif\u001b[0m \u001b[0mlayer\u001b[0m \u001b[1;33m!=\u001b[0m \u001b[1;34m'softmax_cross'\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 52\u001b[1;33m         \u001b[0mx\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mlayers\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mlayer\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mforward\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mx\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     53\u001b[0m     \u001b[1;32mreturn\u001b[0m \u001b[0mx\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     54\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m<ipython-input-9-35d786f50bd6>\u001b[0m in \u001b[0;36mforward\u001b[1;34m(self, x)\u001b[0m\n\u001b[0;32m     58\u001b[0m     \u001b[0moutput_width\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;33m(\u001b[0m\u001b[0mx\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mshape\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;36m3\u001b[0m\u001b[1;33m]\u001b[0m \u001b[1;33m+\u001b[0m \u001b[1;36m2\u001b[0m\u001b[1;33m*\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mpad\u001b[0m \u001b[1;33m-\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mfilter\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mshape\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;36m3\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m//\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mstride\u001b[0m \u001b[1;33m+\u001b[0m \u001b[1;36m1\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     59\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 60\u001b[1;33m     \u001b[0mimage_col\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mim2col\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mx\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mfilter\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mstride\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mpad\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     61\u001b[0m     \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0minput\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mimage_col\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     62\u001b[0m     \u001b[0mfilter_col\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mfilter\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mreshape\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mfilter\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mshape\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;36m0\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m-\u001b[0m\u001b[1;36m1\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mT\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m<ipython-input-7-afd53f53cd03>\u001b[0m in \u001b[0;36mim2col\u001b[1;34m(input_image, filter, stride, pad)\u001b[0m\n\u001b[0;32m     16\u001b[0m       \u001b[0mx_max\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mj\u001b[0m \u001b[1;33m+\u001b[0m \u001b[0mstride\u001b[0m \u001b[1;33m*\u001b[0m \u001b[0moutput_width\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     17\u001b[0m       \u001b[0moutput_col\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m:\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mi\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mj\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m:\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m:\u001b[0m\u001b[1;33m]\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mpad_img\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m:\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mi\u001b[0m\u001b[1;33m:\u001b[0m \u001b[0my_max\u001b[0m\u001b[1;33m:\u001b[0m \u001b[0mstride\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mj\u001b[0m\u001b[1;33m:\u001b[0m\u001b[0mx_max\u001b[0m\u001b[1;33m:\u001b[0m\u001b[0mstride\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 18\u001b[1;33m   \u001b[0moutput_col\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0moutput_col\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mtranspose\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;36m0\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;36m4\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;36m5\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;36m1\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;36m2\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;36m3\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mreshape\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0minput_image\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mshape\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;36m0\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m*\u001b[0m\u001b[0moutput_height\u001b[0m\u001b[1;33m*\u001b[0m\u001b[0moutput_width\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m-\u001b[0m\u001b[1;36m1\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     19\u001b[0m   \u001b[1;32mreturn\u001b[0m \u001b[0moutput_col\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     20\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mMemoryError\u001b[0m: Unable to allocate 5.15 GiB for an array with shape (48000, 24, 24, 1, 5, 5) and data type float64"
     ]
    }
   ],
   "source": [
    "#train\n",
    "model = Two_layer_CNN(20,(5,5),0,1)\n",
    "\n",
    "batch = 100\n",
    "iteration = X_train1.shape[0]//batch \n",
    "epoch = 20\n",
    "w = ['w1','b1','w2','b2','w3','b3']\n",
    "lr = 0.1\n",
    "# iteration는 epoch를 나누어서 실행하는 횟수\n",
    "\n",
    "train_loss =[]\n",
    "valid_loss= []\n",
    "train_acc = []\n",
    "valid_acc = []\n",
    "x_plot = []\n",
    "n = 0\n",
    "\n",
    "\n",
    "#train\n",
    "for i in range(iteration*epoch):\n",
    "  batch_size = np.random.choice(X_train1.shape[0], batch) #array로 return\n",
    "  X_train_b = X_train1[batch_size]\n",
    "  Y_train_b = Y_train1[batch_size]\n",
    "  print(X_train_b.shape)\n",
    "  print(Y_train_b.shape)\n",
    "  #batch_size만큼 한번 진행\n",
    "  gradients = model.back_propagate_train(X_train_b, Y_train_b)\n",
    "\n",
    "  #param updates\n",
    "  for j in w:\n",
    "    model.weights[j] -= lr * gradients[j]\n",
    "  \n",
    "  '''if i % epoch == 0:\n",
    "    print('-')\n",
    "    x_plot.append(n) #count epoch\n",
    "    n+=1\n",
    "    train_l = model.loss(X_train1,Y_train1) #전체 trainset loss계산\n",
    "    valid_l = model.loss(X_train_valid, Y_train_valid)\n",
    "    train_loss.append(train_l)\n",
    "    valid_loss.append(valid_l)\n",
    "    print(\"train loss: \",train_l,\"valid loss: \", valid_l)\n",
    "    train_a = model.accuracy(X_train1,Y_train1)\n",
    "    valid_a = model.accuracy(X_train_valid, Y_train_valid)\n",
    "    train_acc.append(train_a)\n",
    "    valid_acc.append(valid_a)\n",
    "    print(\"train accuracy: \",train_a,\"valid accuracy: \", valid_a)'''"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "xnQrKJqrqztS"
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "accelerator": "GPU",
  "colab": {
   "collapsed_sections": [],
   "name": "HW2_딥러닝_201811111.ipynb",
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
